---
title: "K-Means Clustering Tutorial: Customer Demographic Data"
description: |
  In this post, we introduce what k-means clustering is, how it works in R, how to interpret
  the output, and the limitations associated with such unsupervised machine learning modelling
author:
  - name: Jonathan Choo
    Affiliation: University of Nottingham, Malaysia
date: 2022-04-19
output:
  distill::distill_article:
    self_contained: false
---

Welcome to this short introduction to k-means! First, let me explain what k-means is to give you a better idea on what we will be learning here. 

K-means clustering is a form of **unsupervised machine learning** clustering algorithm which falls under the "partitioning clustering" umbrella. Unlike supervised machine learning, unsupervised ML does not have access to ground truth to compare the output of the clustering algorithm to the true labels to evaluate its performance. We only want to try to investigate the structure of the data by grouping the data points into distinct subgroups that are as similar together as possible. It is a very popular ML clustering algorithm, and very simple to implement in any data set. The other type of clustering is Hierachical clustering, which we will not be touching on here in this post. However, within partitioning clustering, we also have another algorithm called Fuzzy C-Means clustering. 

The main difference between these two algorithms is that K-means clustering assumes that every data point belongs to one single "cluster". Fuzzy C-Means clustering, on the other hand, relaxes this assumption and provides leeway for some data points to be in two or more clusters. Where you would use K-means clustering for understanding simple patterns in the data set (i.e., what are the characteristics of certain groups), you would use Fuzzy C-Means clustering when the group membership criteria are not as clear cut. In both cases, the objective is straightforward, group similar data points together to uncover underlying patterns.

For the purposes of this tutorial, we will just focus on K-means clustering.

For K-means to perform its function, it looks for a fixed number (*k*) of clusters in a dataset. A cluster refers to a collection of data points aggregated together because of certain similarities. You first provide an initial *k* value to determine the preliminary model fit. Based on the accuracy of this model, you then increase or decrease the number of clusters that the model should output. We will cover the optimal method to determining the best *k* value, but for now, understand that you provide an arbitrary number of *k* and develop your model from that.

Let's begin by first understanding what kind of data we are working with. You can download the data from [Kaggle](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(dplyr)
library(tidyverse)
library(cluster)
library(factoextra)
library(gridExtra)
library(GGally)
library(plotly)

```


```{r Input Data, echo=TRUE}
df <- read.csv("Mall_Customers.csv")
head(df)
```

Here, we have four usable data columns: Gender, Age, Annual income and Spending Score. For us to generate meaningful k-means clusters, we first need to ensure that the data we have are numbers, not factors or characters. Because Gender is in characters, we either can filter out Males and Females into their separate data sets, or, we can include them into the analysis by dummy-coding them. We will include them into the analysis by dummy coding them

```{r Filtering, echo=TRUE}
df$Gender[df$Gender == "Male"] <- 1
df$Gender[df$Gender == "Female"] <- 2
df$Gender <- as.numeric(df$Gender)
```
Because CustomerID is meaningless, merely as a way to differentiate customers, we should remove it from the dataframe to ensure only the relevant data is used for clustering

```{r Remove CustomerID, echo=TRUE}
df <- df[,2:5]
head(df)
```

Our dataframe is now prepared for clustering analysis. Before we proceed, let us try to understand what we are trying to learn from this analysis. In the dataframe, you can see the age, annual income and spending score attached to each customer. One insightful data that we can try to garner from this analysis is to determine the characteristics of subgroups. For example:

* Would older adults with a higher annual income have a higher spending score or would they spend less? 
* Would there be any difference when we compare between genders? 

These are some questions that we can answer based on the clustering analysis that we will implement. Now, let us load in the required packages and run the clustering analysis

```{r K-Means Clustering 1, echo=TRUE}
library(cluster)

model <- kmeans(df, centers = 5, nstart = 20)

```

Let's break this down step-by-step:

1. We called the kmeans function from the cluster package
2. Kmeans function accepts several arguments, the first is to indicate what dataframe the analysis will be based on, in this case "df"
 + The other two arguments **centers** and **nstart** are core arguments in the k-means analysis. 
 + *centers* = Determines the number of centroids in a given dataset. Centroids are imaginary or real locations representing the center of a cluster
 + *nstart* = Specifies the number of random data sets used to run the algorithm. Optionally, you can also explicitly determine how many times this process runs by including a *iter.max* argument (default = 10). [Andrea Grianti](https://andrea-grianti.medium.com/kmeans-parameters-in-rstudio-explained-c493ec5a05df) provides an excellent delineation between *nstart* and *interations*, both have similar but distinct meanings:
 
 >if you want 3 clusters and you specify nstart = 10 it extracts 3 sets of data, 10 times, and for each of these times, the algorithm is run (up to iter.max = # of iterations) and the cost function is evaluated so that the lowest is then chosen as the result - Andrea Grianti -
 
3. In the above function, we *arbitrarily* determined the number of centers to be 5 and to sample our dataset using 5 hypothetical centroids 20 times to find the setting with the minimum amount of variance (i.e., within-cluster sum of squares). Because we did not determine the number of max interations, it defaults to 10 interations, that is, it runs the sampling for the minimum within-cluster SS 10 times.

```{r K-Means Clustering 2, echo=FALSE}
model

```

